{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fba6d8",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.981 · TFM · Aula 1</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2024-2 · Màster universitari en Ciència de dades (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'informàtica, multimèdia i telecomunicació</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "<div style=\"text-align: center; margin-top: 40px;\">\n",
    "    <h1>Aplicación para ayuda a la conducción con deep learning</h1>\n",
    "</div>\n",
    "\n",
    "### ARCHIVO 10: Entrenamiento frenos\n",
    "\n",
    "Entrena un modelo clasificador binario.\n",
    "\n",
    "Código que ejecuta el entrenamiento a partir de imágenes en carpetas definidas. Modelo a entrenar: EfficientNet B0.\n",
    "\n",
    "Código ejecutado en plataforma Visual Studio Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b5e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llibreries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ea153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dades\n",
    "\n",
    "Dades = \"Llums_Cotxe\" # Carpeta amb subcarpetes per classe\n",
    "\n",
    "# Bloc per a la normalització d'imatges\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3817bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe per a crear un dataset\n",
    "\n",
    "class BrakeDataset(Dataset):\n",
    "    def __init__(self, paths, labels):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = cv2.imread(self.paths[i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = transform(img)\n",
    "        return img, torch.tensor(self.labels[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llegeix carpetes\n",
    "\n",
    "# Funció per a recopilar les imatges i torna datasets separats\n",
    "def get_data():\n",
    "    paths, labels = [], []\n",
    "    for label, folder in enumerate(['NoFreno', 'Freno']):\n",
    "        full = os.path.join(Dades, folder)\n",
    "        for f in os.listdir(full):\n",
    "            if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "                paths.append(os.path.join(full, f))\n",
    "                labels.append(label)\n",
    "    return train_test_split(paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dades i loaders\n",
    "train_paths, test_paths, train_labels, test_labels = get_data()\n",
    "train_loader = DataLoader(BrakeDataset(train_paths, train_labels), batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b77417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Càrrega model\n",
    "\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "# Paràmetres\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malve\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\malve\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.6083\n",
      "Epoch 2: 0.4083\n",
      "Epoch 3: 0.2647\n",
      "Epoch 4: 0.1498\n",
      "Epoch 5: 0.1041\n",
      "Mètriques de validació:\n",
      "Accuracy : 0.9545454545454546\n",
      "Precision: 0.92\n",
      "Recall   : 0.92\n",
      "F1 Score : 0.92\n",
      "Fi d'entrenament\n"
     ]
    }
   ],
   "source": [
    "# Entrenament\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.unsqueeze(1).cuda()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model, \"DetectBrake3.pt\")\n",
    "\n",
    "# Avaluació\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in DataLoader(BrakeDataset(test_paths, test_labels), batch_size=16):\n",
    "        x = x.cuda()\n",
    "        y_true.extend(y)\n",
    "        out = model(x)\n",
    "        probs = torch.sigmoid(out).cpu()\n",
    "        y_pred.extend((probs > 0.5).int().squeeze().tolist())\n",
    "\n",
    "# Mètriques\n",
    "print(\"Mètriques de validació:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_true, y_pred))\n",
    "print(\"F1 Score :\", f1_score(y_true, y_pred))\n",
    "\n",
    "print(\"Fi d'entrenament\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
